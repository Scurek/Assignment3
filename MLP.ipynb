{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJHWVso0DzLM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7749c609-8796-4896-8049-bddd22d5a256"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'Assignment3': No such file or directory\n",
            "Cloning into 'Assignment3'...\n",
            "remote: Enumerating objects: 4297, done.\u001b[K\n",
            "remote: Counting objects: 100% (4297/4297), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2390/2390), done.\u001b[K\n",
            "remote: Total 4297 (delta 33), reused 4293 (delta 29), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (4297/4297), 54.80 MiB | 13.90 MiB/s, done.\n",
            "Resolving deltas: 100% (33/33), done.\n"
          ]
        }
      ],
      "source": [
        "!rm -r Assignment3\n",
        "!git clone https://hrosc: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@github.com/hrosc/Assignment3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wjeRhrQBcBZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSb-OWYsDzLT"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "epochs = 100"
      ],
      "metadata": {
        "id": "F8KTC5gSlb6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKgFdzdfDzLU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9d56b50-875b-4cce-c5c5-cb240d5c1451"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting train features...\n",
            "Extracting test features...\n"
          ]
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "import glob\n",
        "import re\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def get_annotations(annot_f):\n",
        "  d = {}\n",
        "  with open(annot_f) as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "      (key, val) = line.split(',')\n",
        "      d[key] = int(val)\n",
        "  return d\n",
        "\n",
        "base_path = \"Assignment3/data/\"\n",
        "dataset = \"perfectly_detected_ears\"\n",
        "annotations_path = base_path + dataset + \"/annotations/recognition/ids.csv\"\n",
        "train_path = base_path + dataset + \"/train\"\n",
        "test_path = base_path + dataset + \"/test\"\n",
        "\n",
        "im_list = sorted(glob.glob(train_path + '/*.png', recursive=True))\n",
        "im_list_test = sorted(glob.glob(test_path + '/*.png', recursive=True))\n",
        "cla_d = get_annotations(annotations_path)\n",
        "\n",
        "import Assignment3.feature_extractors.lbp.extractor as lbp_ext\n",
        "lbp = lbp_ext.LBP(radius=2)\n",
        "\n",
        "feature_extractor = lbp\n",
        "\n",
        "x_train = []\n",
        "y_train = []\n",
        "print(\"Extracting train features...\")\n",
        "for im_name in im_list:\n",
        "    img = cv2.imread(im_name)\n",
        "    \n",
        "    ann_name = '/'.join(re.split(r'/|\\\\', im_name)[3:])\n",
        "    #print(ann_name)\n",
        "    y_train.append(int(cla_d[ann_name]) - 1)\n",
        "    train_features = feature_extractor.extract(img)\n",
        "    x_train.append(train_features)\n",
        "\n",
        "x_test = []\n",
        "y_test = []\n",
        "print(\"Extracting test features...\")\n",
        "for im_name in im_list_test:\n",
        "    img = cv2.imread(im_name)\n",
        "    \n",
        "    ann_name = '/'.join(re.split(r'/|\\\\', im_name)[3:])\n",
        "    #print(ann_name)\n",
        "    y_test.append(int(cla_d[ann_name]) - 1)\n",
        "    test_features = feature_extractor.extract(img)\n",
        "    x_test.append(test_features)\n",
        "\n",
        "x_train_base = np.asarray(x_train)\n",
        "y_train_base = np.asarray(y_train, dtype=np.uint8)\n",
        "x_test_base = np.asarray(x_test)\n",
        "y_test_base = np.asarray(y_test, dtype=np.uint8)\n",
        "\n",
        "# the data, split between train and test sets\n",
        "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# (x_train1, y_train1), (x_test1, y_test1) = mnist.load_data()\n",
        "num_classes = len(np.unique(y_train_base))\n",
        "input_size = x_train_base.shape[1]\n",
        "# for later\n",
        "x_test_orig = x_test\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQkNbb1FDzLY"
      },
      "source": [
        "## KERAS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1t5r4Cj7DzLY",
        "outputId": "1af53357-40ba-4368-c33f-d30e07f4ac17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "750 train samples\n",
            "250 test samples\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "#from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout, Conv2D, MaxPooling2D, Flatten\n",
        "# For training MLP model we need 1D flattened images\n",
        "#x_train = x_train.reshape(60000, 784)\n",
        "#x_test = x_test.reshape(10000, 784)\n",
        "\n",
        "x_train = x_train_base.astype('float32')\n",
        "x_test = x_test_base.astype('float32')\n",
        "#x_train /= 255\n",
        "#x_test /= 255\n",
        "print(x_train_base.shape[0], 'train samples')\n",
        "print(x_test_base.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train_base, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test_base, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IfFq5-VDzLa",
        "outputId": "6545fc71-2818-425e-969e-1c0ce6043b0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "MLP model:\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_16 (Dense)            (None, 10000)             110000    \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 10000)             0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 100)               1000100   \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 100)               0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 100)               0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 10)                1010      \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 10)                0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 100)               1100      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,122,310\n",
            "Trainable params: 1,122,310\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "-----------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(num_classes)\n",
        "model_mlp = Sequential()\n",
        "model_mlp.add(Dense(100, activation='relu', input_shape=(input_size,)))\n",
        "model_mlp.add(Dropout(0.1))\n",
        "model_mlp.add(Dense(100, activation='relu'))\n",
        "model_mlp.add(Dropout(0.1))\n",
        "model_mlp.add(Dense(100, activation='relu'))\n",
        "model_mlp.add(Dropout(0.1))\n",
        "model_mlp.add(Dense(100, activation='relu'))\n",
        "model_mlp.add(Dropout(0.1))\n",
        "model_mlp.add(Dense(num_classes, activation='softmax'))\n",
        "print(\"MLP model:\")\n",
        "model_mlp.summary()\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
        "model_mlp.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "print(\"\\n-----------------------------------------------------------------------\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kVNQ6QsDzLb"
      },
      "outputs": [],
      "source": [
        "'''Trains a simple deep NN on the MNIST dataset.\n",
        "Gets to 98.40% test accuracy after 20 epochs\n",
        "(there is *a lot* of margin for parameter tuning).\n",
        "2 seconds per epoch on a K520 GPU.\n",
        "'''\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_mlp = model_mlp.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "print(history_mlp.history)\n",
        "print('Train loss:', history_mlp.history['loss'])\n",
        "loss = history_mlp.history['loss']\n",
        "val_loss = history_mlp.history['val_loss']\n",
        "print('Train accuracy:', history_mlp.history['accuracy'])\n",
        "print('Test loss:', history_mlp.history['val_loss'])\n",
        "print('Test accuracy:', history_mlp.history['val_accuracy'])\n",
        "\n",
        "acc = history_mlp.history['accuracy']\n",
        "val_acc = history_mlp.history['val_accuracy']\n",
        "x = range(len(acc))\n",
        "\n",
        "plt.figure()\n",
        "plt.title(\"Loss\")\n",
        "plt.plot(x, loss, 'b')\n",
        "plt.plot(x, val_loss, 'r')\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.title(\"Accuracy\")\n",
        "plt.plot(x, acc, 'b')\n",
        "plt.plot(x, val_acc, 'r')\n",
        "plt.show()\n",
        "\n",
        "model_mlp.save_weights('mlp_weights.h5')\n",
        "\n",
        "score = model_mlp.evaluate(x_test, y_test, verbose=0)\n",
        "print(score)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "Me_YUMjxDzLd"
      },
      "outputs": [],
      "source": [
        "model_mlp.load_weights('mlp_weights.h5')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "prediction_mlp = model_mlp.predict(np.array([x_test[ID]]))\n",
        "print(\"MLP prediction: \")\n",
        "df = pd.DataFrame(prediction_mlp, columns=range(0,10))\n",
        "display(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XOPxEZrDzLb"
      },
      "source": [
        "## SCIKIT"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler  \n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(x_train_base)\n",
        "x_train = scaler.transform(x_train_base)\n",
        "x_test = scaler.transform(x_test_base)  "
      ],
      "metadata": {
        "id": "aGDHtoDQ8O_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = MLPClassifier(solver='lbfgs', \n",
        "                    random_state=1, \n",
        "                    hidden_layer_sizes=(100, 100, 100), \n",
        "                    max_iter=5000,\n",
        "                    learning_rate='adaptive', verbose=True\n",
        "                    ).fit(x_train, y_train_base)\n",
        "print(\"Score:\", clf.score(x_test, y_test_base))\n",
        "# print(clf.predict([x_test[0]]), y_test_base[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViTAy4ubvZiX",
        "outputId": "1bf1e775-04a4-4407-8a42-23335f6c04ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: 0.052\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JmcfT2AcwifQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "name": "MLP.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "xSb-OWYsDzLT",
        "nH9eb-VT02Q9"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}